"use strict";(globalThis.webpackChunkhumanoid_robotics_course=globalThis.webpackChunkhumanoid_robotics_course||[]).push([[6183],{6720:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>o,contentTitle:()=>l,default:()=>m,frontMatter:()=>r,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"module-3-digital-twin-simulation/practical-lab","title":"Module 3: Practical Lab - Digital Twin Simulation Environments","description":"Lab Overview","source":"@site/docs/module-3-digital-twin-simulation/practical-lab.md","sourceDirName":"module-3-digital-twin-simulation","slug":"/module-3-digital-twin-simulation/practical-lab","permalink":"/humanoid-robotics-course/docs/module-3-digital-twin-simulation/practical-lab","draft":false,"unlisted":false,"editUrl":"https://github.com/RizSheik/humanoid-robotics-course/edit/main/docs/module-3-digital-twin-simulation/practical-lab.md","tags":[],"version":"current","frontMatter":{}}');var t=i(4848),s=i(8453);const r={},l="Module 3: Practical Lab - Digital Twin Simulation Environments",o={},c=[{value:"Lab Overview",id:"lab-overview",level:2},{value:"Learning Objectives",id:"learning-objectives",level:3},{value:"Required Software/Tools",id:"required-softwaretools",level:3},{value:"Lab Duration",id:"lab-duration",level:3},{value:"Lab 1: Gazebo Simulation Environment Setup",id:"lab-1-gazebo-simulation-environment-setup",level:2},{value:"Objective",id:"objective",level:3},{value:"Setup",id:"setup",level:3},{value:"Implementation Steps",id:"implementation-steps",level:3},{value:"Code Template",id:"code-template",level:3},{value:"Analysis",id:"analysis",level:3},{value:"Lab 2: Unity Simulation Environment Implementation",id:"lab-2-unity-simulation-environment-implementation",level:2},{value:"Objective",id:"objective-1",level:3},{value:"Setup",id:"setup-1",level:3},{value:"Implementation Steps",id:"implementation-steps-1",level:3},{value:"Code Template",id:"code-template-1",level:3},{value:"Analysis",id:"analysis-1",level:3},{value:"Lab 3: Isaac Sim Advanced Environment",id:"lab-3-isaac-sim-advanced-environment",level:2},{value:"Objective",id:"objective-2",level:3},{value:"Setup",id:"setup-2",level:3},{value:"Implementation Steps",id:"implementation-steps-2",level:3},{value:"Python Template",id:"python-template",level:3},{value:"Analysis",id:"analysis-2",level:3},{value:"Lab 4: Cross-Platform Comparison and Validation",id:"lab-4-cross-platform-comparison-and-validation",level:2},{value:"Objective",id:"objective-3",level:3},{value:"Setup",id:"setup-3",level:3},{value:"Implementation Steps",id:"implementation-steps-3",level:3},{value:"Analysis Template",id:"analysis-template",level:3},{value:"Analysis",id:"analysis-3",level:3},{value:"Lab 5: Advanced Simulation Techniques Implementation",id:"lab-5-advanced-simulation-techniques-implementation",level:2},{value:"Objective",id:"objective-4",level:3},{value:"Setup",id:"setup-4",level:3},{value:"Implementation Steps",id:"implementation-steps-4",level:3},{value:"Code Template",id:"code-template-2",level:3},{value:"Lab Report Requirements",id:"lab-report-requirements",level:2},{value:"Assessment Criteria",id:"assessment-criteria",level:2},{value:"Troubleshooting Tips",id:"troubleshooting-tips",level:2},{value:"Extensions and Advanced Challenges",id:"extensions-and-advanced-challenges",level:2},{value:"References and Further Reading",id:"references-and-further-reading",level:2}];function d(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.header,{children:(0,t.jsx)(e.h1,{id:"module-3-practical-lab---digital-twin-simulation-environments",children:"Module 3: Practical Lab - Digital Twin Simulation Environments"})}),"\n",(0,t.jsx)(e.h2,{id:"lab-overview",children:"Lab Overview"}),"\n",(0,t.jsx)(e.p,{children:"This practical lab provides hands-on experience with implementing digital twin simulation environments using Gazebo, Unity, and Isaac Sim. Students will work with all three platforms to understand their strengths and applications in robotics development, with a focus on creating accurate, efficient, and transferable simulation environments."}),"\n",(0,t.jsx)(e.h3,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsx)(e.p,{children:"After completing this lab, students will be able to:"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"Set up and configure simulation environments in Gazebo, Unity, and Isaac Sim"}),"\n",(0,t.jsx)(e.li,{children:"Create accurate robot models with realistic physics and sensor simulation"}),"\n",(0,t.jsx)(e.li,{children:"Implement advanced simulation techniques like domain randomization and system identification"}),"\n",(0,t.jsx)(e.li,{children:"Compare the strengths and weaknesses of different simulation platforms"}),"\n",(0,t.jsx)(e.li,{children:"Validate simulation models against real-world data"}),"\n",(0,t.jsx)(e.li,{children:"Design and implement sim-to-real transfer strategies"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"required-softwaretools",children:"Required Software/Tools"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Gazebo Harmonic"})," or later with ROS 2 integration"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Unity Hub"})," with Unity 2021.3 LTS and robotics packages"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"NVIDIA Isaac Sim"})," with Omniverse platform"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"ROS 2 Humble Hawksbill"})," or later"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Python 3.11+"})," and ",(0,t.jsx)(e.strong,{children:"C++17"})," for custom implementations"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Git"})," for version control"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Docker"})," for Isaac Sim container deployment"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"lab-duration",children:"Lab Duration"}),"\n",(0,t.jsx)(e.p,{children:"This lab is designed for 18-22 hours of work, typically spread over 3-4 weeks."}),"\n",(0,t.jsx)(e.h2,{id:"lab-1-gazebo-simulation-environment-setup",children:"Lab 1: Gazebo Simulation Environment Setup"}),"\n",(0,t.jsx)(e.h3,{id:"objective",children:"Objective"}),"\n",(0,t.jsx)(e.p,{children:"Set up a Gazebo simulation environment with realistic physics and sensor simulation for a wheeled robot."}),"\n",(0,t.jsx)(e.h3,{id:"setup",children:"Setup"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"Install Gazebo Harmonic with ROS 2 Humble"}),"\n",(0,t.jsx)(e.li,{children:"Create a simple wheeled robot model (e.g., differential drive)"}),"\n",(0,t.jsx)(e.li,{children:"Configure physics parameters and sensor simulation"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"implementation-steps",children:"Implementation Steps"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"Create URDF model of a differential drive robot with appropriate inertial properties"}),"\n",(0,t.jsx)(e.li,{children:"Configure Gazebo plugins for differential drive control"}),"\n",(0,t.jsx)(e.li,{children:"Add sensor models (camera, LIDAR, IMU) with realistic noise parameters"}),"\n",(0,t.jsx)(e.li,{children:"Create a world file with obstacles and terrain features"}),"\n",(0,t.jsx)(e.li,{children:"Test the simulation and ensure proper ROS 2 topic bridging"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"code-template",children:"Code Template"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-xml",children:'\x3c!-- differential_drive_robot.urdf --\x3e\n<?xml version="1.0"?>\n<robot name="differential_drive_robot" xmlns:xacro="http://www.ros.org/wiki/xacro">\n  \n  \x3c!-- Base Link --\x3e\n  <link name="base_link">\n    <inertial>\n      <mass value="10.0"/>\n      <origin xyz="0 0 0.1"/>\n      <inertia ixx="0.1" ixy="0" ixz="0" iyy="0.1" iyz="0" izz="0.1"/>\n    </inertial>\n    \n    <visual>\n      <origin xyz="0 0 0.1"/>\n      <geometry>\n        <box size="0.5 0.3 0.2"/>\n      </geometry>\n      <material name="blue">\n        <color rgba="0 0 1 1"/>\n      </material>\n    </visual>\n    \n    <collision>\n      <origin xyz="0 0 0.1"/>\n      <geometry>\n        <box size="0.5 0.3 0.2"/>\n      </geometry>\n    </collision>\n  </link>\n\n  \x3c!-- Left Wheel --\x3e\n  <link name="left_wheel">\n    <inertial>\n      <mass value="1.0"/>\n      <inertia ixx="0.01" ixy="0" ixz="0" iyy="0.01" iyz="0" izz="0.01"/>\n    </inertial>\n    \n    <visual>\n      <origin xyz="0 0 0"/>\n      <geometry>\n        <cylinder radius="0.1" length="0.05"/>\n      </geometry>\n    </visual>\n    \n    <collision>\n      <origin xyz="0 0 0"/>\n      <geometry>\n        <cylinder radius="0.1" length="0.05"/>\n      </geometry>\n    </collision>\n  </link>\n\n  \x3c!-- Right Wheel --\x3e\n  <link name="right_wheel">\n    <inertial>\n      <mass value="1.0"/>\n      <inertia ixx="0.01" ixy="0" ixz="0" iyy="0.01" iyz="0" izz="0.01"/>\n    </inertial>\n    \n    <visual>\n      <origin xyz="0 0 0"/>\n      <geometry>\n        <cylinder radius="0.1" length="0.05"/>\n      </geometry>\n    </visual>\n    \n    <collision>\n      <origin xyz="0 0 0"/>\n      <geometry>\n        <cylinder radius="0.1" length="0.05"/>\n      </geometry>\n    </collision>\n  </link>\n\n  \x3c!-- Joints --\x3e\n  <joint name="left_wheel_joint" type="continuous">\n    <parent link="base_link"/>\n    <child link="left_wheel"/>\n    <origin xyz="0.15 0.175 0"/>\n    <axis xyz="0 0 1"/>\n  </joint>\n\n  <joint name="right_wheel_joint" type="continuous">\n    <parent link="base_link"/>\n    <child link="right_wheel"/>\n    <origin xyz="0.15 -0.175 0"/>\n    <axis xyz="0 0 1"/>\n  </joint>\n\n  \x3c!-- Gazebo Plugins --\x3e\n  <gazebo>\n    <plugin filename="libignition-gazebo-diff-drive-system.so" name="ignition::gazebo::systems::DiffDrive">\n      <left_joint>left_wheel_joint</left_joint>\n      <right_joint>right_wheel_joint</right_joint>\n      <wheel_separation>0.35</wheel_separation>\n      <wheel_radius>0.1</wheel_radius>\n      <odom_publish_frequency>30</odom_publish_frequency>\n      <topic>cmd_vel</topic>\n      <odom_topic>odom</odom_topic>\n      <tf_topic>tf</tf_topic>\n    </plugin>\n  </gazebo>\n\n  \x3c!-- Camera Sensor --\x3e\n  <gazebo reference="base_link">\n    <sensor name="camera" type="camera">\n      <camera>\n        <horizontal_fov>1.047</horizontal_fov>\n        <image>\n          <width>640</width>\n          <height>480</height>\n          <format>R8G8B8</format>\n        </image>\n        <clip>\n          <near>0.1</near>\n          <far>10</far>\n        </clip>\n      </camera>\n      <always_on>true</always_on>\n      <update_rate>30</update_rate>\n      <visualize>true</visualize>\n    </sensor>\n  </gazebo>\n\n</robot>\n'})}),"\n",(0,t.jsx)(e.h3,{id:"analysis",children:"Analysis"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Evaluate the realism of the physics simulation"}),"\n",(0,t.jsx)(e.li,{children:"Test sensor accuracy and noise characteristics"}),"\n",(0,t.jsx)(e.li,{children:"Analyze the performance of the simulation (real-time factor)"}),"\n",(0,t.jsx)(e.li,{children:"Verify ROS 2 topic communication"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"lab-2-unity-simulation-environment-implementation",children:"Lab 2: Unity Simulation Environment Implementation"}),"\n",(0,t.jsx)(e.h3,{id:"objective-1",children:"Objective"}),"\n",(0,t.jsx)(e.p,{children:"Create a photorealistic Unity simulation environment with advanced rendering and perception capabilities."}),"\n",(0,t.jsx)(e.h3,{id:"setup-1",children:"Setup"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"Install Unity Hub and Unity 2021.3 LTS"}),"\n",(0,t.jsx)(e.li,{children:"Install Unity Robotics packages (ROS TCP Connector, Perception)"}),"\n",(0,t.jsx)(e.li,{children:"Create a scene with realistic lighting and materials"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"implementation-steps-1",children:"Implementation Steps"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"Set up a new Unity scene with outdoor environment"}),"\n",(0,t.jsx)(e.li,{children:"Create a 3D model of the robot (or import from assets)"}),"\n",(0,t.jsx)(e.li,{children:"Configure advanced lighting with realistic shadows"}),"\n",(0,t.jsx)(e.li,{children:"Implement perception pipeline with synthetic data generation"}),"\n",(0,t.jsx)(e.li,{children:"Connect to ROS using TCP connector"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"code-template-1",children:"Code Template"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:'// UnityRobotController.cs\nusing UnityEngine;\nusing Unity.Robotics.ROSTCPConnector;\nusing RosMessageTypes.Geometry;\n\npublic class UnityRobotController : MonoBehaviour\n{\n    [Header("Robot Configuration")]\n    public Transform robotBase;\n    public WheelCollider[] wheels;\n    public float maxMotorTorque = 50f;\n    public float maxSteeringAngle = 30f;\n\n    [Header("ROS Connection")]\n    public string rosIP = "127.0.0.1";\n    public int rosPort = 10000;\n\n    private ROSConnection ros;\n    private float motorTorque = 0f;\n    private float steering = 0f;\n\n    void Start()\n    {\n        // Connect to ROS\n        ros = ROSConnection.GetOrCreateInstance();\n        ros.Initialize(rosIP, rosPort);\n        \n        // Subscribe to command topic\n        ros.Subscribe<TwistMsg>("/cmd_vel", ReceiveVelocityCommand);\n        \n        // Publish odometry\n        InvokeRepeating("PublishOdometry", 0f, 0.05f);  // 20 Hz\n    }\n\n    void ReceiveVelocityCommand(TwistMsg cmd)\n    {\n        // Convert ROS velocity command to Unity controls\n        motorTorque = cmd.linear.x * 50f;  // Scale factor\n        steering = cmd.angular.z * 0.5f;   // Scale factor\n    }\n\n    void Update()\n    {\n        // Apply motor and steering to wheels\n        foreach (var wheel in wheels)\n        {\n            wheel.motorTorque = motorTorque;\n            \n            if (wheel.gameObject.name.Contains("Front"))\n            {\n                wheel.steerAngle = steering;\n            }\n        }\n    }\n\n    void PublishOdometry()\n    {\n        // Calculate odometry data\n        var odomData = new OdometryMsg();\n        odomData.header.stamp = new TimeMsg();\n        odomData.header.frame_id = "odom";\n        odomData.child_frame_id = "base_link";\n        \n        // Set position and orientation\n        odomData.pose.pose.position = new Vector3Msg(\n            transform.position.x,\n            transform.position.y,\n            transform.position.z\n        );\n        \n        odomData.pose.pose.orientation = new QuaternionMsg(\n            transform.rotation.x,\n            transform.rotation.y,\n            transform.rotation.z,\n            transform.rotation.w\n        );\n        \n        // Set velocities\n        odomData.twist.twist.linear = new Vector3Msg(\n            rigidbody.velocity.x,\n            rigidbody.velocity.y,\n            rigidbody.velocity.z\n        );\n        \n        // Publish odometry\n        ros.Publish("/odom", odomData);\n    }\n}\n'})}),"\n",(0,t.jsx)(e.h3,{id:"analysis-1",children:"Analysis"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Evaluate the photorealistic rendering quality"}),"\n",(0,t.jsx)(e.li,{children:"Test perception pipeline and synthetic data generation"}),"\n",(0,t.jsx)(e.li,{children:"Analyze the performance of Unity simulation (frame rate)"}),"\n",(0,t.jsx)(e.li,{children:"Compare Unity's rendering advantages over Gazebo"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"lab-3-isaac-sim-advanced-environment",children:"Lab 3: Isaac Sim Advanced Environment"}),"\n",(0,t.jsx)(e.h3,{id:"objective-2",children:"Objective"}),"\n",(0,t.jsx)(e.p,{children:"Implement an AI-powered robotics simulation environment in Isaac Sim with perception and control capabilities."}),"\n",(0,t.jsx)(e.h3,{id:"setup-2",children:"Setup"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"Install Isaac Sim using Docker or direct installation"}),"\n",(0,t.jsx)(e.li,{children:"Set up Omniverse environment and extensions"}),"\n",(0,t.jsx)(e.li,{children:"Create a complex scene with multiple objects and dynamic elements"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"implementation-steps-2",children:"Implementation Steps"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"Create a USD scene with advanced materials and lighting"}),"\n",(0,t.jsx)(e.li,{children:"Configure robot with accurate kinematics and dynamics"}),"\n",(0,t.jsx)(e.li,{children:"Implement Isaac ROS perception pipeline"}),"\n",(0,t.jsx)(e.li,{children:"Train a simple navigation policy using Isaac Gym"}),"\n",(0,t.jsx)(e.li,{children:"Generate synthetic datasets for computer vision tasks"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"python-template",children:"Python Template"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'# isaac_sim_robot.py\nimport omni\nfrom pxr import Gf, Usd, UsdGeom\nfrom omni.isaac.core import World\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\nfrom omni.isaac.core.utils.nucleus import get_assets_root_path\nfrom omni.isaac.core.robots import Robot\nfrom omni.isaac.core.utils.prims import get_prim_at_path\nfrom omni.isaac.core.prims import RigidPrimView\nfrom omni.isaac.sensor import _sensor as _sensor\nimport numpy as np\nimport carb\n\nclass IsaacSimRobotEnvironment:\n    def __init__(self):\n        self.world = World(stage_units_in_meters=1.0)\n        self._setup_scene()\n        \n    def _setup_scene(self):\n        """Set up the Isaac Sim environment"""\n        # Add ground plane\n        self.world.scene.add_default_ground_plane()\n        \n        # Add robot\n        assets_root_path = get_assets_root_path()\n        if assets_root_path is None:\n            carb.log_error("Could not find Isaac Sim assets folder")\n            return\n            \n        # Use a simple robot for this example\n        robot_path = "/World/Robot"\n        robot_prim_path = f"{robot_path}/Robot"\n        \n        # We\'ll create a simple cube-based robot structure\n        robot_stage_path = "/Isaac/Robots/Carter/carter_nucleus.usd"\n        if assets_root_path:\n            full_path = assets_root_path + robot_stage_path\n            add_reference_to_stage(usd_path=full_path, prim_path=robot_path)\n        \n        # Add objects for the robot to interact with\n        self._add_objects()\n        \n    def _add_objects(self):\n        """Add objects to the scene"""\n        # Add a target object\n        from omni.isaac.core.objects import DynamicCuboid\n        \n        self.target = DynamicCuboid(\n            prim_path="/World/Target",\n            name="target",\n            position=np.array([1.5, 1.5, 0.5]),\n            size=np.array([0.2, 0.2, 0.2]),\n            color=np.array([1.0, 0.0, 0.0])\n        )\n        self.world.scene.add(self.target)\n        \n        # Add obstacles\n        self.obstacle1 = DynamicCuboid(\n            prim_path="/World/Obstacle1",\n            name="obstacle1",\n            position=np.array([1.0, 0.0, 0.5]),\n            size=np.array([0.3, 0.3, 0.3]),\n            color=np.array([0.0, 1.0, 0.0])\n        )\n        self.world.scene.add(self.obstacle1)\n        \n    def reset(self):\n        """Reset the environment to initial state"""\n        self.world.reset()\n        \n        # Reset robot position\n        # This would depend on the specific robot implementation\n        pass\n        \n    def step(self, action):\n        """Execute an action and return the new state"""\n        # Apply action to robot\n        # This would involve sending commands to the robot\'s joints/controllers\n        \n        # Step the physics world\n        self.world.step(render=True)\n        \n        # Get new observations\n        observation = self._get_observation()\n        reward = self._calculate_reward()\n        done = self._is_done()\n        \n        return observation, reward, done, {}\n    \n    def _get_observation(self):\n        """Get current observation from the environment"""\n        # Get robot state\n        # Get sensor data (camera, LIDAR, etc.)\n        # Format into observation space\n        \n        return np.zeros(10)  # Placeholder\n    \n    def _calculate_reward(self):\n        """Calculate reward for the current state"""\n        # Calculate based on task (navigation, manipulation, etc.)\n        return 0.0  # Placeholder\n    \n    def _is_done(self):\n        """Check if the episode is done"""\n        return False  # Placeholder\n\ndef run_isaac_sim_robot():\n    """Main function to run the Isaac Sim environment"""\n    env = IsaacSimRobotEnvironment()\n    \n    # Run simulation for a few steps\n    for i in range(100):\n        obs, reward, done, info = env.step(np.zeros(2))  # Dummy action\n        if done:\n            env.reset()\n    \n    # Clean up\n    env.world.clear()\n'})}),"\n",(0,t.jsx)(e.h3,{id:"analysis-2",children:"Analysis"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Evaluate the photorealistic rendering and physics simulation"}),"\n",(0,t.jsx)(e.li,{children:"Test the Isaac ROS integration and perception pipeline"}),"\n",(0,t.jsx)(e.li,{children:"Analyze the synthetic data generation capabilities"}),"\n",(0,t.jsx)(e.li,{children:"Compare the AI training capabilities with other platforms"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"lab-4-cross-platform-comparison-and-validation",children:"Lab 4: Cross-Platform Comparison and Validation"}),"\n",(0,t.jsx)(e.h3,{id:"objective-3",children:"Objective"}),"\n",(0,t.jsx)(e.p,{children:"Compare simulation results across different platforms and validate against real-world data."}),"\n",(0,t.jsx)(e.h3,{id:"setup-3",children:"Setup"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"Run the same robot control task in all three simulation environments"}),"\n",(0,t.jsx)(e.li,{children:"Collect data from each simulation"}),"\n",(0,t.jsx)(e.li,{children:"Compare the results and analyze differences"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"implementation-steps-3",children:"Implementation Steps"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"Implement the same navigation task in Gazebo, Unity, and Isaac Sim"}),"\n",(0,t.jsx)(e.li,{children:"Use the same control algorithm in each environment"}),"\n",(0,t.jsx)(e.li,{children:"Collect performance metrics (trajectory accuracy, timing, resource usage)"}),"\n",(0,t.jsx)(e.li,{children:"Compare sensor data quality and realism"}),"\n",(0,t.jsx)(e.li,{children:"Analyze the simulation-to-simulation differences"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"analysis-template",children:"Analysis Template"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"# comparison_analysis.py\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nclass SimulationComparisonAnalyzer:\n    def __init__(self, gazebo_data, unity_data, isaac_data):\n        self.gazebo_data = gazebo_data\n        self.unity_data = unity_data\n        self.isaac_data = isaac_data\n        \n    def compare_performance_metrics(self):\n        \"\"\"Compare performance metrics across platforms\"\"\"\n        metrics = {\n            'gazebo': {\n                'real_time_factor': self.calculate_rtf(self.gazebo_data),\n                'avg_cpu_usage': self.calculate_cpu_usage(self.gazebo_data),\n                'avg_memory_usage': self.calculate_memory_usage(self.gazebo_data)\n            },\n            'unity': {\n                'real_time_factor': self.calculate_rtf(self.unity_data),\n                'avg_cpu_usage': self.calculate_cpu_usage(self.unity_data),\n                'avg_memory_usage': self.calculate_memory_usage(self.unity_data)\n            },\n            'isaac_sim': {\n                'real_time_factor': self.calculate_rtf(self.isaac_data),\n                'avg_cpu_usage': self.calculate_cpu_usage(self.isaac_data),\n                'avg_memory_usage': self.calculate_memory_usage(self.isaac_data)\n            }\n        }\n        \n        return metrics\n    \n    def compare_sensor_quality(self):\n        \"\"\"Compare sensor data quality across platforms\"\"\"\n        # Calculate signal-to-noise ratios, accuracy, etc.\n        gazebo_camera_quality = self.evaluate_camera_quality(self.gazebo_data['camera'])\n        unity_camera_quality = self.evaluate_camera_quality(self.unity_data['camera'])\n        isaac_camera_quality = self.evaluate_camera_quality(self.isaac_data['camera'])\n        \n        return {\n            'gazebo': gazebo_camera_quality,\n            'unity': unity_camera_quality,\n            'isaac_sim': isaac_camera_quality\n        }\n    \n    def visualize_comparison(self):\n        \"\"\"Create comparison visualizations\"\"\"\n        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n        \n        # Performance comparison\n        platforms = ['Gazebo', 'Unity', 'Isaac Sim']\n        rtf_values = [\n            self.calculate_rtf(self.gazebo_data),\n            self.calculate_rtf(self.unity_data),\n            self.calculate_rtf(self.isaac_data)\n        ]\n        \n        axes[0, 0].bar(platforms, rtf_values)\n        axes[0, 0].set_title('Real-Time Factor Comparison')\n        axes[0, 0].set_ylabel('RTF')\n        \n        # Sensor accuracy comparison\n        sensor_acc = [\n            self.evaluate_sensor_accuracy(self.gazebo_data),\n            self.evaluate_sensor_accuracy(self.unity_data),\n            self.evaluate_sensor_accuracy(self.isaac_data)\n        ]\n        \n        axes[0, 1].bar(platforms, sensor_acc)\n        axes[0, 1].set_title('Sensor Accuracy Comparison')\n        axes[0, 1].set_ylabel('Accuracy (lower is better)')\n        \n        # Development complexity\n        # This would be subjective ratings\n        complexity_ratings = [2, 4, 5]  # 1-5 scale, 5 being most complex\n        axes[1, 0].bar(platforms, complexity_ratings)\n        axes[1, 0].set_title('Development Complexity')\n        axes[1, 0].set_ylabel('Complexity Rating (1-5)')\n        \n        # Rendering quality\n        # This would be based on subjective evaluation or metrics like FPS\n        rendering_quality = [3, 5, 5]  # 1-5 scale, 5 being best\n        axes[1, 1].bar(platforms, rendering_quality)\n        axes[1, 1].set_title('Rendering Quality')\n        axes[1, 1].set_ylabel('Quality Rating (1-5)')\n        \n        plt.tight_layout()\n        plt.savefig('simulation_comparison.png', dpi=300, bbox_inches='tight')\n        plt.show()\n\ndef conduct_cross_platform_analysis():\n    \"\"\"Conduct cross-platform simulation analysis\"\"\"\n    # This function would:\n    # 1. Run identical experiments in all three platforms\n    # 2. Collect performance and quality metrics\n    # 3. Generate comparison reports\n    \n    # Load data from all platforms\n    # gazebo_data = load_gazebo_experiment_data()\n    # unity_data = load_unity_experiment_data() \n    # isaac_data = load_isaac_sim_experiment_data()\n    \n    # analyzer = SimulationComparisonAnalyzer(gazebo_data, unity_data, isaac_data)\n    # metrics = analyzer.compare_performance_metrics()\n    # sensor_qualities = analyzer.compare_sensor_quality()\n    # analyzer.visualize_comparison()\n    \n    # Generate comparison report\n    print(\"Cross-platform analysis completed\")\n    print(\"For full analysis, implement the data loading and processing functions\")\n"})}),"\n",(0,t.jsx)(e.h3,{id:"analysis-3",children:"Analysis"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Compare the performance metrics (real-time factor, resource usage)"}),"\n",(0,t.jsx)(e.li,{children:"Evaluate the quality of sensor simulation in each platform"}),"\n",(0,t.jsx)(e.li,{children:"Analyze the development complexity and time requirements"}),"\n",(0,t.jsx)(e.li,{children:"Determine the best use cases for each platform"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"lab-5-advanced-simulation-techniques-implementation",children:"Lab 5: Advanced Simulation Techniques Implementation"}),"\n",(0,t.jsx)(e.h3,{id:"objective-4",children:"Objective"}),"\n",(0,t.jsx)(e.p,{children:"Implement advanced digital twin simulation techniques including domain randomization, system identification, and sim-to-real transfer."}),"\n",(0,t.jsx)(e.h3,{id:"setup-4",children:"Setup"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"Choose one of the simulation platforms as primary environment"}),"\n",(0,t.jsx)(e.li,{children:"Implement domain randomization techniques"}),"\n",(0,t.jsx)(e.li,{children:"Apply system identification to improve simulation accuracy"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"implementation-steps-4",children:"Implementation Steps"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"Implement domain randomization for the robot simulation"}),"\n",(0,t.jsx)(e.li,{children:"Collect data from real robot (or realistic mock data)"}),"\n",(0,t.jsx)(e.li,{children:"Apply system identification to calibrate simulation parameters"}),"\n",(0,t.jsx)(e.li,{children:"Validate sim-to-real transfer capability"}),"\n",(0,t.jsx)(e.li,{children:"Document the process and results"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"code-template-2",children:"Code Template"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'# advanced_techniques.py\nimport numpy as np\nfrom scipy.optimize import minimize\nimport matplotlib.pyplot as plt\n\nclass AdvancedSimulationTechniques:\n    def __init__(self, simulation_environment):\n        self.sim_env = simulation_environment\n        self.randomization_params = self._initialize_randomization_params()\n        self.system_id_data = []\n        \n    def _initialize_randomization_params(self):\n        """Initialize parameters for domain randomization"""\n        return {\n            \'mass_range\': (0.8, 1.2),  # 80% to 120% of nominal\n            \'friction_range\': (0.1, 1.0),\n            \'inertia_range\': (0.9, 1.1),\n            \'sensor_noise_multiplier\': (0.5, 2.0),\n            \'lighting_variation\': (0.5, 2.0),\n            \'material_properties_range\': (0.8, 1.2)\n        }\n    \n    def apply_domain_randomization(self, episode_number=0):\n        """Apply domain randomization to simulation parameters"""\n        # Randomly select parameters within ranges\n        random_params = {}\n        for param_name, (min_val, max_val) in self.randomization_params.items():\n            if \'range\' in param_name or param_name.endswith(\'_multiplier\'):\n                # Random sampling\n                random_params[param_name] = np.random.uniform(min_val, max_val)\n            elif param_name == \'lighting_variation\':\n                # Apply to lighting if available\n                random_params[param_name] = np.random.uniform(min_val, max_val)\n        \n        # Apply parameters to simulation\n        self.sim_env.update_parameters(random_params)\n        \n        return random_params\n    \n    def collect_system_identification_data(self, real_robot_interface, n_samples=1000):\n        """Collect data for system identification"""\n        print("Collecting system identification data...")\n        \n        for i in range(n_samples):\n            # Apply random control input\n            control_input = self.generate_random_control()\n            \n            # Get real robot response\n            real_state = real_robot_interface.apply_control_and_get_state(control_input)\n            \n            # Get simulation prediction\n            sim_state = self.sim_env.apply_control_and_get_state(control_input)\n            \n            # Store data pair\n            self.system_id_data.append({\n                \'control\': control_input,\n                \'real_state\': real_state,\n                \'sim_state\': sim_state,\n                \'error\': np.linalg.norm(real_state - sim_state)\n            })\n            \n            if i % 100 == 0:\n                print(f"Collected {i}/{n_samples} data points")\n    \n    def optimize_simulation_parameters(self):\n        """Optimize simulation parameters to match real robot"""\n        def objective_function(params):\n            # Apply parameters to simulation\n            self.sim_env.apply_parameter_vector(params)\n            \n            # Calculate total error across all data points\n            total_error = 0\n            for data_point in self.system_id_data:\n                sim_state = self.sim_env.apply_control_and_get_state(\n                    data_point[\'control\']\n                )\n                error = np.linalg.norm(data_point[\'real_state\'] - sim_state)\n                total_error += error\n            \n            return total_error / len(self.system_id_data)\n        \n        # Get initial parameter vector from sim_env\n        initial_params = self.sim_env.get_parameter_vector()\n        \n        # Optimize parameters\n        result = minimize(\n            objective_function,\n            initial_params,\n            method=\'BFGS\',\n            options={\'disp\': True}\n        )\n        \n        # Apply optimized parameters\n        self.sim_env.apply_parameter_vector(result.x)\n        \n        print(f"Optimization completed. Final error: {result.fun}")\n        return result\n    \n    def validate_sim_to_real_transfer(self, policy, n_trials=10):\n        """Validate policy transfer from simulation to reality"""\n        sim_successes = 0\n        real_successes = 0\n        \n        print("Validating sim-to-real transfer...")\n        \n        for trial in range(n_trials):\n            print(f"Trial {trial + 1}/{n_trials}")\n            \n            # Test in simulation\n            sim_success = self.test_policy_in_simulation(policy)\n            if sim_success:\n                sim_successes += 1\n            \n            # Test on real system (or high-fidelity simulation)\n            real_success = self.test_policy_on_real_system(policy)\n            if real_success:\n                real_successes += 1\n        \n        sim_rate = sim_successes / n_trials\n        real_rate = real_successes / n_trials\n        \n        print(f"Simulation success rate: {sim_rate:.2%}")\n        print(f"Real system success rate: {real_rate:.2%}")\n        print(f"Transfer gap: {sim_rate - real_rate:.2%}")\n        \n        return {\n            \'sim_success_rate\': sim_rate,\n            \'real_success_rate\': real_rate,\n            \'transfer_gap\': sim_rate - real_rate\n        }\n    \n    def generate_random_control(self):\n        """Generate random control input for system ID"""\n        # Example: random wheel velocities for differential drive\n        return np.random.uniform(-1.0, 1.0, size=2)\n    \n    def test_policy_in_simulation(self, policy):\n        """Test policy in simulation environment"""\n        # Reset simulation\n        self.sim_env.reset()\n        \n        # Run policy for episode\n        for step in range(100):  # 100 steps per episode\n            state = self.sim_env.get_state()\n            action = policy(state)\n            self.sim_env.apply_action(action)\n            \n            if self.sim_env.is_episode_done():\n                break\n        \n        return self.sim_env.get_reward() > 0.5  # Success threshold\n    \n    def test_policy_on_real_system(self, policy):\n        """Test policy on real system (mock implementation)"""\n        # In practice, this would connect to real robot\n        # For this exercise, we\'ll simulate with added realism\n        success_prob = 0.7  # Simulated success probability\n        return np.random.random() < success_prob\n\n# Example usage\ndef implement_advanced_techniques_example():\n    """Example implementation of advanced simulation techniques"""\n    \n    # Assuming we have a simulation environment\n    # sim_env = initialize_simulation_environment()\n    \n    # Initialize advanced techniques\n    # advanced_sim = AdvancedSimulationTechniques(sim_env)\n    \n    # Apply domain randomization\n    # for episode in range(100):\n    #     random_params = advanced_sim.apply_domain_randomization(episode)\n    #     # Run training episode with randomized environment\n    #     pass\n    \n    # Collect data for system identification\n    # real_robot = initialize_real_robot_interface()  # Mock interface\n    # advanced_sim.collect_system_identification_data(real_robot, n_samples=500)\n    \n    # Optimize simulation parameters\n    # optimization_result = advanced_sim.optimize_simulation_parameters()\n    \n    # Validate sim-to-real transfer\n    # dummy_policy = lambda state: np.random.uniform(-1, 1, 2)  # Random policy\n    # transfer_results = advanced_sim.validate_sim_to_real_transfer(dummy_policy)\n    \n    print("Advanced simulation techniques implemented")\n    print("For full implementation, connect to actual simulation and real robot environments")\n'})}),"\n",(0,t.jsx)(e.h2,{id:"lab-report-requirements",children:"Lab Report Requirements"}),"\n",(0,t.jsx)(e.p,{children:"For each lab exercise, students must submit:"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Implementation Documentation"})," (20%):"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Complete code with proper documentation"}),"\n",(0,t.jsx)(e.li,{children:"Step-by-step implementation guide"}),"\n",(0,t.jsx)(e.li,{children:"Configuration files and environment setup"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Performance Analysis"})," (35%):"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Quantitative analysis of simulation performance"}),"\n",(0,t.jsx)(e.li,{children:"Comparison metrics between platforms"}),"\n",(0,t.jsx)(e.li,{children:"Resource usage analysis"}),"\n",(0,t.jsx)(e.li,{children:"Real-time factor measurements"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Validation Results"})," (25%):"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Data comparing simulation to expected behavior"}),"\n",(0,t.jsx)(e.li,{children:"Analysis of sensor and physics accuracy"}),"\n",(0,t.jsx)(e.li,{children:"Sim-to-real transfer validation results"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"System Design Report"})," (20%):"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Architecture of the implemented simulation system"}),"\n",(0,t.jsx)(e.li,{children:"Design decisions and rationale"}),"\n",(0,t.jsx)(e.li,{children:"Challenges encountered and solutions"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"assessment-criteria",children:"Assessment Criteria"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Implementation quality and correctness (40%)"}),"\n",(0,t.jsx)(e.li,{children:"Performance analysis and optimization (30%)"}),"\n",(0,t.jsx)(e.li,{children:"Understanding of different simulation platforms (20%)"}),"\n",(0,t.jsx)(e.li,{children:"Documentation and code quality (10%)"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"troubleshooting-tips",children:"Troubleshooting Tips"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Gazebo Issues"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Ensure proper ROS 2 environment setup"}),"\n",(0,t.jsx)(e.li,{children:"Check plugin compatibility"}),"\n",(0,t.jsx)(e.li,{children:"Verify URDF/SDF model validity"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Unity Issues"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Verify graphics card compatibility"}),"\n",(0,t.jsx)(e.li,{children:"Check ROS TCP Connector setup"}),"\n",(0,t.jsx)(e.li,{children:"Ensure proper physics configuration"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Isaac Sim Issues"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Verify NVIDIA GPU and drivers"}),"\n",(0,t.jsx)(e.li,{children:"Check Omniverse connection"}),"\n",(0,t.jsx)(e.li,{children:"Ensure proper asset paths"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"General Issues"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Monitor system resource usage"}),"\n",(0,t.jsx)(e.li,{children:"Check network connectivity for ROS connections"}),"\n",(0,t.jsx)(e.li,{children:"Verify correct time synchronization"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"extensions-and-advanced-challenges",children:"Extensions and Advanced Challenges"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Multi-Robot Simulation"}),": Extend to multiple robots with coordination"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Complex Environments"}),": Create dynamic, changing environments"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Advanced Physics"}),": Implement soft-body physics or fluid dynamics"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"AI Integration"}),": Train reinforcement learning policies in simulation"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Real Robot Integration"}),": Connect with actual robotic hardware"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"references-and-further-reading",children:"References and Further Reading"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:["Gazebo Harmonic Documentation: ",(0,t.jsx)(e.a,{href:"http://gazebosim.org/",children:"http://gazebosim.org/"})]}),"\n",(0,t.jsxs)(e.li,{children:["Unity Robotics Hub: ",(0,t.jsx)(e.a,{href:"https://unity.com/solutions/robotics",children:"https://unity.com/solutions/robotics"})]}),"\n",(0,t.jsxs)(e.li,{children:["NVIDIA Isaac Sim Documentation: ",(0,t.jsx)(e.a,{href:"https://docs.omniverse.nvidia.com/isaacsim/",children:"https://docs.omniverse.nvidia.com/isaacsim/"})]}),"\n",(0,t.jsxs)(e.li,{children:["ROS 2 Documentation: ",(0,t.jsx)(e.a,{href:"https://docs.ros.org/",children:"https://docs.ros.org/"})]}),"\n",(0,t.jsx)(e.li,{children:"CoppeliaSim (V-REP) Documentation for alternative perspectives"}),"\n"]})]})}function m(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>r,x:()=>l});var a=i(6540);const t={},s=a.createContext(t);function r(n){const e=a.useContext(s);return a.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function l(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:r(n.components),a.createElement(s.Provider,{value:e},n.children)}}}]);