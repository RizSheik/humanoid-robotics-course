"use strict";(globalThis.webpackChunkhumanoid_robotics_course=globalThis.webpackChunkhumanoid_robotics_course||[]).push([[8403],{7041:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>u,frontMatter:()=>r,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"module-3-digital-twin-simulation/chapter-3","title":"Chapter 3: Unity - Visualization-Rich Simulation Environments","description":"Learning Objectives","source":"@site/docs/module-3-digital-twin-simulation/chapter-3.md","sourceDirName":"module-3-digital-twin-simulation","slug":"/module-3-digital-twin-simulation/chapter-3","permalink":"/humanoid-robotics-course/docs/module-3-digital-twin-simulation/chapter-3","draft":false,"unlisted":false,"editUrl":"https://github.com/RizSheik/humanoid-robotics-course/edit/main/docs/module-3-digital-twin-simulation/chapter-3.md","tags":[],"version":"current","frontMatter":{}}');var o=i(4848),a=i(8453);const r={},s="Chapter 3: Unity - Visualization-Rich Simulation Environments",l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"3.1 Introduction to Unity for Robotics",id:"31-introduction-to-unity-for-robotics",level:2},{value:"3.1.1 Unity in the Robotics Context",id:"311-unity-in-the-robotics-context",level:3},{value:"3.1.2 Unity vs Other Simulation Platforms",id:"312-unity-vs-other-simulation-platforms",level:3},{value:"3.1.3 Unity Robotics Ecosystem",id:"313-unity-robotics-ecosystem",level:3},{value:"3.2 Setting Up Unity for Robotics Simulation",id:"32-setting-up-unity-for-robotics-simulation",level:2},{value:"3.2.1 System Requirements",id:"321-system-requirements",level:3},{value:"3.2.2 Installation Process",id:"322-installation-process",level:3},{value:"3.2.3 Recommended Packages",id:"323-recommended-packages",level:3},{value:"3.3 Creating Robot Models in Unity",id:"33-creating-robot-models-in-unity",level:2},{value:"3.3.1 Importing Robot Models",id:"331-importing-robot-models",level:3},{value:"3.3.2 Physics Configuration for Robots",id:"332-physics-configuration-for-robots",level:3},{value:"3.3.3 Animation and Joint Control",id:"333-animation-and-joint-control",level:3},{value:"3.4 Environment Design and Physics",id:"34-environment-design-and-physics",level:2},{value:"3.4.1 Creating Realistic Environments",id:"341-creating-realistic-environments",level:3},{value:"3.4.2 Physics Simulation Parameters",id:"342-physics-simulation-parameters",level:3},{value:"3.4.3 Terrain and Complex Environments",id:"343-terrain-and-complex-environments",level:3},{value:"3.5 Sensor Simulation in Unity",id:"35-sensor-simulation-in-unity",level:2},{value:"3.5.1 Camera Sensor Simulation",id:"351-camera-sensor-simulation",level:3},{value:"3.5.2 LIDAR Sensor Simulation",id:"352-lidar-sensor-simulation",level:3},{value:"3.5.3 IMU Sensor Simulation",id:"353-imu-sensor-simulation",level:3},{value:"3.6 ROS Integration with Unity",id:"36-ros-integration-with-unity",level:2},{value:"3.6.1 ROS-TCP-Connector Setup",id:"361-ros-tcp-connector-setup",level:3},{value:"3.6.2 Message Conversion Utilities",id:"362-message-conversion-utilities",level:3},{value:"3.7 Performance Optimization",id:"37-performance-optimization",level:2},{value:"3.7.1 Rendering Optimization",id:"371-rendering-optimization",level:3},{value:"3.7.2 Physics Optimization",id:"372-physics-optimization",level:3},{value:"3.8 Advanced Simulation Features",id:"38-advanced-simulation-features",level:2},{value:"3.8.1 Domain Randomization",id:"381-domain-randomization",level:3},{value:"3.8.2 Synthetic Data Generation",id:"382-synthetic-data-generation",level:3},{value:"Chapter Summary",id:"chapter-summary",level:2},{value:"Key Terms",id:"key-terms",level:2},{value:"Exercises",id:"exercises",level:2},{value:"References",id:"references",level:2}];function d(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"chapter-3-unity---visualization-rich-simulation-environments",children:"Chapter 3: Unity - Visualization-Rich Simulation Environments"})}),"\n",(0,o.jsx)("div",{className:"robotDiagram",children:(0,o.jsx)("img",{src:"../../../img/book-image/Illustration_explaining_Physical_AI_huma_1 (1).jpg",alt:"Humanoid Robot",style:{borderRadius:"50px",width:"900px",height:"350px",margin:"10px auto",display:"block"}})}),"\n",(0,o.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,o.jsx)(e.p,{children:"After completing this chapter, students will be able to:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Set up and configure Unity simulation environments for robotics"}),"\n",(0,o.jsx)(e.li,{children:"Create realistic visual environments with accurate physics"}),"\n",(0,o.jsx)(e.li,{children:"Implement sensor simulations with Unity's rendering pipeline"}),"\n",(0,o.jsx)(e.li,{children:"Develop custom robotics assets and environments in Unity"}),"\n",(0,o.jsx)(e.li,{children:"Integrate Unity simulations with ROS 2 communication systems"}),"\n",(0,o.jsx)(e.li,{children:"Optimize Unity environments for real-time robotics simulation"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"31-introduction-to-unity-for-robotics",children:"3.1 Introduction to Unity for Robotics"}),"\n",(0,o.jsx)(e.p,{children:"Unity has emerged as a powerful platform for creating visualization-rich simulation environments for robotics, particularly for applications requiring high-fidelity graphics, photorealistic rendering, or complex environmental scenarios. Originally developed for game development, Unity's real-time rendering capabilities, extensive asset ecosystem, and physics engine make it suitable for simulating robotic perception, human-robot interaction, and complex environments."}),"\n",(0,o.jsx)(e.h3,{id:"311-unity-in-the-robotics-context",children:"3.1.1 Unity in the Robotics Context"}),"\n",(0,o.jsx)(e.p,{children:"Unity provides several advantages for robotics simulation:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Photorealistic Rendering"}),": Essential for training computer vision algorithms"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Extensive Asset Library"}),": Thousands of pre-made models and environments"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Flexible Scripting System"}),": Using C# for custom robot behaviors"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Physics Engine"}),": Built-in physics simulation with configurable parameters"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Cross-Platform Support"}),": Deploy to various hardware configurations"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"User Interaction"}),": Natural interfaces for human-in-the-loop scenarios"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"312-unity-vs-other-simulation-platforms",children:"3.1.2 Unity vs Other Simulation Platforms"}),"\n",(0,o.jsxs)(e.table,{children:[(0,o.jsx)(e.thead,{children:(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.th,{children:"Aspect"}),(0,o.jsx)(e.th,{children:"Unity"}),(0,o.jsx)(e.th,{children:"Gazebo"}),(0,o.jsx)(e.th,{children:"Other Platforms"})]})}),(0,o.jsxs)(e.tbody,{children:[(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:"Rendering Quality"}),(0,o.jsx)(e.td,{children:"High"}),(0,o.jsx)(e.td,{children:"Moderate"}),(0,o.jsx)(e.td,{children:"Varies"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:"Physics Accuracy"}),(0,o.jsx)(e.td,{children:"Good"}),(0,o.jsx)(e.td,{children:"Excellent"}),(0,o.jsx)(e.td,{children:"Varies"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:"Sensor Simulation"}),(0,o.jsx)(e.td,{children:"Good*"}),(0,o.jsx)(e.td,{children:"Excellent"}),(0,o.jsx)(e.td,{children:"Good"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:"Realism"}),(0,o.jsx)(e.td,{children:"High"}),(0,o.jsx)(e.td,{children:"Moderate"}),(0,o.jsx)(e.td,{children:"Varies"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:"Asset Creation"}),(0,o.jsx)(e.td,{children:"Easy"}),(0,o.jsx)(e.td,{children:"Complex"}),(0,o.jsx)(e.td,{children:"Varies"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:"Development Speed"}),(0,o.jsx)(e.td,{children:"Fast"}),(0,o.jsx)(e.td,{children:"Moderate"}),(0,o.jsx)(e.td,{children:"Varies"})]})]})]}),"\n",(0,o.jsx)(e.p,{children:"*Unity sensors require custom implementation but can achieve high fidelity"}),"\n",(0,o.jsx)(e.h3,{id:"313-unity-robotics-ecosystem",children:"3.1.3 Unity Robotics Ecosystem"}),"\n",(0,o.jsx)(e.p,{children:"Unity provides several tools for robotics applications:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Unity Robotics Hub"}),": Centralized access to robotics packages and samples"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Unity ML-Agents"}),": For reinforcement learning applications"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"ROS#"}),": For ROS/ROS 2 communication"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Unity Perception"}),": For generating synthetic training data"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Open Source Robotics (OSR) Integration"}),": For standardized interfaces"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"32-setting-up-unity-for-robotics-simulation",children:"3.2 Setting Up Unity for Robotics Simulation"}),"\n",(0,o.jsx)(e.h3,{id:"321-system-requirements",children:"3.2.1 System Requirements"}),"\n",(0,o.jsx)(e.p,{children:"To run Unity effectively for robotics simulation:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"OS"}),": Windows 10+, macOS 10.14+, or Ubuntu 18.04+"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"CPU"}),": 64-bit processor with SSE2 support"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Memory"}),": 8GB+ RAM (16GB+ recommended for complex scenes)"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"GPU"}),": DirectX 10 or OpenGL 3.3+ compatible graphics card"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Storage"}),": 20GB+ free space for Unity installation and projects"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"322-installation-process",children:"3.2.2 Installation Process"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsx)(e.li,{children:"Download Unity Hub from Unity's website"}),"\n",(0,o.jsx)(e.li,{children:"Install Unity Hub and create an account"}),"\n",(0,o.jsx)(e.li,{children:"Use Unity Hub to install Unity version 2021.3 LTS or later (recommended for stability)"}),"\n",(0,o.jsx)(e.li,{children:"Install required modules: Windows/Linux/Mac Build Support, Visual Studio integration"}),"\n",(0,o.jsx)(e.li,{children:"Install Unity robotics packages via Package Manager"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"323-recommended-packages",children:"3.2.3 Recommended Packages"}),"\n",(0,o.jsx)(e.p,{children:"For robotics applications, install these packages:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"ROS-TCP-Connector"}),": For ROS/ROS 2 communication"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Unity Perception"}),": For synthetic data generation"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Open Robotics Integration"}),": Standardized interfaces"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Universal Render Pipeline (URP)"}),": For optimized rendering"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"XR Toolkit"}),": If developing VR/AR applications"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"33-creating-robot-models-in-unity",children:"3.3 Creating Robot Models in Unity"}),"\n",(0,o.jsx)(e.h3,{id:"331-importing-robot-models",children:"3.3.1 Importing Robot Models"}),"\n",(0,o.jsx)(e.p,{children:"Unity can import robot models from various formats:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// Example of importing and setting up a robot model\nusing UnityEngine;\n\npublic class RobotModelSetup : MonoBehaviour\n{\n    [Header("Robot Configuration")]\n    public string robotName;\n    public Vector3 initialPosition = Vector3.zero;\n    public Quaternion initialRotation = Quaternion.identity;\n\n    [Header("Joint Configuration")]\n    public Transform[] jointTransforms;\n    public string[] jointNames;\n    public float[] jointLimitsMin;\n    public float[] jointLimitsMax;\n\n    void Start()\n    {\n        SetupRobot();\n    }\n\n    void SetupRobot()\n    {\n        // Position and orient the robot\n        transform.position = initialPosition;\n        transform.rotation = initialRotation;\n\n        // Configure joints (simplified example)\n        ConfigureJoints();\n    }\n\n    void ConfigureJoints()\n    {\n        for (int i = 0; i < jointTransforms.Length; i++)\n        {\n            // Add joint constraints using configurable joints\n            var joint = jointTransforms[i].GetComponent<ConfigurableJoint>();\n            if (joint != null)\n            {\n                // Configure joint limits based on real robot specifications\n                joint.angularXLimit = new SoftJointLimit\n                {\n                    limit = jointLimitsMax[i]\n                };\n                \n                joint.angularXDrive = new JointDrive\n                {\n                    positionSpring = 10000f, // Stiffness\n                    positionDamper = 100f   // Damping\n                };\n            }\n        }\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h3,{id:"332-physics-configuration-for-robots",children:"3.3.2 Physics Configuration for Robots"}),"\n",(0,o.jsx)(e.p,{children:"Configuring physics properties for realistic robot behavior:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// Physics configuration script for robot parts\nusing UnityEngine;\n\n[RequireComponent(typeof(Rigidbody))]\npublic class RobotPhysicsConfig : MonoBehaviour\n{\n    [Header("Physics Properties")]\n    public float mass = 1.0f;\n    public PhysicMaterial physicMaterial;\n    \n    [Header("Drag Settings")]\n    public float drag = 0.1f;\n    public float angularDrag = 0.05f;\n    \n    [Header("Collision Settings")]\n    public bool useInterpolation = true;\n    public CollisionDetectionMode collisionDetectionMode = CollisionDetectionMode.ContinuousDynamic;\n    \n    void Start()\n    {\n        SetupPhysics();\n    }\n\n    void SetupPhysics()\n    {\n        Rigidbody rb = GetComponent<Rigidbody>();\n        rb.mass = mass;\n        rb.drag = drag;\n        rb.angularDrag = angularDrag;\n        rb.interpolation = useInterpolation ? RigidbodyInterpolation.Interpolate : RigidbodyInterpolation.None;\n        rb.collisionDetectionMode = collisionDetectionMode;\n        \n        // Assign physic material if specified\n        if (physicMaterial != null && GetComponent<Collider>() != null)\n        {\n            GetComponent<Collider>().material = physicMaterial;\n        }\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h3,{id:"333-animation-and-joint-control",children:"3.3.3 Animation and Joint Control"}),"\n",(0,o.jsx)(e.p,{children:"Creating systems for robot joint control and animation:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:"// Joint controller for Unity robot\nusing UnityEngine;\n\npublic class RobotJointController : MonoBehaviour\n{\n    [System.Serializable]\n    public class JointConfig\n    {\n        public string jointName;\n        public Transform jointTransform;\n        public float minAngle = -90f;\n        public float maxAngle = 90f;\n        public float currentAngle;\n        public float targetAngle;\n        public float maxSpeed = 100f; // degrees per second\n    }\n\n    public JointConfig[] joints;\n    public bool usePhysics = false;\n\n    void Update()\n    {\n        UpdateJoints();\n    }\n\n    void UpdateJoints()\n    {\n        for (int i = 0; i < joints.Length; i++)\n        {\n            var joint = joints[i];\n            \n            // Move toward target angle\n            joint.currentAngle = Mathf.MoveTowards(\n                joint.currentAngle, \n                joint.targetAngle, \n                joint.maxSpeed * Time.deltaTime\n            );\n            \n            // Apply rotation (assuming rotation around Y axis)\n            Vector3 rotation = joint.jointTransform.localEulerAngles;\n            rotation.y = joint.currentAngle;\n            joint.jointTransform.localEulerAngles = rotation;\n        }\n    }\n\n    // Method to set joint target angles\n    public void SetJointTarget(int jointIndex, float angle)\n    {\n        if (jointIndex >= 0 && jointIndex < joints.Length)\n        {\n            joints[jointIndex].targetAngle = Mathf.Clamp(angle, \n                joints[jointIndex].minAngle, \n                joints[jointIndex].maxAngle);\n        }\n    }\n\n    // Method to get current joint angles\n    public float GetJointAngle(int jointIndex)\n    {\n        if (jointIndex >= 0 && jointIndex < joints.Length)\n        {\n            return joints[jointIndex].currentAngle;\n        }\n        return 0f;\n    }\n}\n"})}),"\n",(0,o.jsx)(e.h2,{id:"34-environment-design-and-physics",children:"3.4 Environment Design and Physics"}),"\n",(0,o.jsx)(e.h3,{id:"341-creating-realistic-environments",children:"3.4.1 Creating Realistic Environments"}),"\n",(0,o.jsx)(e.p,{children:"Unity excels at creating photorealistic environments for robotics training:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// Environment setup script\nusing UnityEngine;\n\npublic class EnvironmentSetup : MonoBehaviour\n{\n    [Header("Environment Configuration")]\n    public Material[] environmentMaterials;\n    public GameObject[] environmentalObjects;\n    \n    [Header("Lighting Setup")]\n    public Light mainLight;\n    public float lightIntensity = 1.0f;\n    public Color lightColor = Color.white;\n    \n    [Header("Physics Environment")]\n    public PhysicMaterial groundMaterial;\n    public float gravityMultiplier = 1.0f;\n\n    void Start()\n    {\n        SetupEnvironment();\n    }\n\n    void SetupEnvironment()\n    {\n        // Configure lighting\n        if (mainLight != null)\n        {\n            mainLight.intensity = lightIntensity;\n            mainLight.color = lightColor;\n            \n            // Add realistic shadows\n            mainLight.shadows = LightShadows.Soft;\n        }\n        \n        // Apply environment materials\n        foreach (var material in environmentMaterials)\n        {\n            // Apply environmental properties\n            if (material != null)\n            {\n                // Set up material properties for physics simulation\n                // (This would be more complex in a real implementation)\n            }\n        }\n        \n        // Configure physics environment\n        Physics.gravity *= gravityMultiplier;\n        \n        // Apply ground material to floor objects\n        ApplyGroundMaterial();\n    }\n\n    void ApplyGroundMaterial()\n    {\n        GameObject[] floors = GameObject.FindGameObjectsWithTag("Floor");\n        foreach (GameObject floor in floors)\n        {\n            Collider floorCollider = floor.GetComponent<Collider>();\n            if (floorCollider != null && groundMaterial != null)\n            {\n                floorCollider.material = groundMaterial;\n            }\n        }\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h3,{id:"342-physics-simulation-parameters",children:"3.4.2 Physics Simulation Parameters"}),"\n",(0,o.jsx)(e.p,{children:"Configuring Unity's physics system for robotics simulation:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// Physics configuration for robotics simulation\nusing UnityEngine;\n\npublic class RoboticsPhysicsConfig : MonoBehaviour\n{\n    [Header("Physics Settings")]\n    public int solverIterations = 6;           // Higher for stable joints\n    public int solverVelocityIterations = 1;   // Higher for stable contacts\n    public float sleepThreshold = 0.005f;      // Lower to detect small movements\n    public float defaultContactOffset = 0.01f; // Small for accurate contacts\n    public float bounceThreshold = 2f;         // Threshold for bouncing\n    public float defaultSolverVelocityIterations = 1;\n\n    void Start()\n    {\n        ConfigurePhysics();\n    }\n\n    void ConfigurePhysics()\n    {\n        Physics.defaultSolverIterations = solverIterations;\n        Physics.defaultSolverVelocityIterations = solverVelocityIterations;\n        Physics.sleepThreshold = sleepThreshold;\n        Physics.defaultContactOffset = defaultContactOffset;\n        Physics.bounceThreshold = bounceThreshold;\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h3,{id:"343-terrain-and-complex-environments",children:"3.4.3 Terrain and Complex Environments"}),"\n",(0,o.jsx)(e.p,{children:"Creating complex outdoor environments:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// Terrain configuration script\nusing UnityEngine;\n\n[RequireComponent(typeof(Terrain))]\npublic class TerrainConfig : MonoBehaviour\n{\n    [Header("Terrain Properties")]\n    public float terrainScale = 100f;\n    public PhysicMaterial terrainMaterial;\n    public Texture2D[] terrainTextures;\n    public float[] textureScales;\n\n    void Start()\n    {\n        ConfigureTerrain();\n    }\n\n    void ConfigureTerrain()\n    {\n        Terrain terrain = GetComponent<Terrain>();\n        \n        // Configure terrain properties\n        terrain.terrainData.size = new Vector3(terrainScale, 20f, terrainScale);\n        \n        // Set up terrain collider with physics material\n        TerrainCollider terrainCollider = GetComponent<TerrainCollider>();\n        if (terrainCollider != null && terrainMaterial != null)\n        {\n            terrainCollider.material = terrainMaterial;\n        }\n        \n        // Configure terrain textures\n        SetupTerrainTextures(terrain);\n    }\n\n    void SetupTerrainTextures(Terrain terrain)\n    {\n        TerrainData terrainData = terrain.terrainData;\n        \n        // Create and assign terrain materials\n        SplatPrototype[] splatPrototypes = new SplatPrototype[terrainTextures.Length];\n        \n        for (int i = 0; i < terrainTextures.Length; i++)\n        {\n            splatPrototypes[i] = new SplatPrototype();\n            splatPrototypes[i].texture = terrainTextures[i];\n            splatPrototypes[i].tileSize = new Vector2(textureScales[i], textureScales[i]);\n        }\n        \n        terrainData.splatPrototypes = splatPrototypes;\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h2,{id:"35-sensor-simulation-in-unity",children:"3.5 Sensor Simulation in Unity"}),"\n",(0,o.jsx)(e.h3,{id:"351-camera-sensor-simulation",children:"3.5.1 Camera Sensor Simulation"}),"\n",(0,o.jsx)(e.p,{children:"Creating realistic camera sensors with Unity's rendering pipeline:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// Unity camera sensor implementation\nusing UnityEngine;\nusing System.Collections;\n\npublic class UnityCameraSensor : MonoBehaviour\n{\n    [Header("Camera Configuration")]\n    public Camera cameraComponent;\n    public int imageWidth = 640;\n    public int imageHeight = 480;\n    public float updateRate = 30f; // FPS\n    public bool addNoise = true;\n    \n    [Header("Noise Configuration")]\n    public float noiseIntensity = 0.01f;\n    public float noiseScale = 0.1f;\n\n    private RenderTexture renderTexture;\n    private float updateInterval;\n    private float lastUpdate;\n\n    void Start()\n    {\n        SetupCamera();\n        CreateRenderTexture();\n        updateInterval = 1.0f / updateRate;\n    }\n\n    void Update()\n    {\n        if (Time.time - lastUpdate >= updateInterval)\n        {\n            CaptureImage();\n            lastUpdate = Time.time;\n        }\n    }\n\n    void SetupCamera()\n    {\n        if (cameraComponent == null)\n        {\n            cameraComponent = GetComponent<Camera>();\n        }\n        \n        if (cameraComponent == null)\n        {\n            cameraComponent = gameObject.AddComponent<Camera>();\n        }\n        \n        cameraComponent.targetTexture = null; // Will be set to render texture\n        cameraComponent.enabled = true;\n    }\n\n    void CreateRenderTexture()\n    {\n        renderTexture = new RenderTexture(imageWidth, imageHeight, 24);\n        renderTexture.Create();\n        cameraComponent.targetTexture = renderTexture;\n    }\n\n    void CaptureImage()\n    {\n        // Capture image to RenderTexture\n        cameraComponent.Render();\n        \n        // Process image (in a real implementation, this would send to ROS)\n        ProcessCapturedImage();\n    }\n\n    void ProcessCapturedImage()\n    {\n        // Create temporary texture to read pixels\n        Texture2D imageTexture = new Texture2D(renderTexture.width, renderTexture.height, \n            TextureFormat.RGB24, false);\n        \n        // Keep current active render texture\n        RenderTexture currentRT = RenderTexture.active;\n        RenderTexture.active = renderTexture;\n        \n        // Read pixels from active render texture\n        imageTexture.ReadPixels(new Rect(0, 0, renderTexture.width, renderTexture.height), 0, 0);\n        imageTexture.Apply();\n        \n        // Restore active render texture\n        RenderTexture.active = currentRT;\n        \n        // Add noise if enabled\n        if (addNoise)\n        {\n            AddImageNoise(imageTexture);\n        }\n        \n        // In a real implementation, convert to ROS message format and publish\n        ConvertAndPublishImage(imageTexture);\n        \n        // Clean up temporary texture\n        Destroy(imageTexture);\n    }\n\n    void AddImageNoise(Texture2D texture)\n    {\n        // Apply noise to image texture\n        Color[] pixels = texture.GetPixels();\n        \n        for (int i = 0; i < pixels.Length; i++)\n        {\n            // Add random noise\n            float noise = Random.Range(-noiseIntensity, noiseIntensity);\n            pixels[i] = new Color(\n                Mathf.Clamp01(pixels[i].r + noise),\n                Mathf.Clamp01(pixels[i].g + noise),\n                Mathf.Clamp01(pixels[i].b + noise)\n            );\n        }\n        \n        texture.SetPixels(pixels);\n        texture.Apply();\n    }\n\n    void ConvertAndPublishImage(Texture2D image)\n    {\n        // Convert Unity image format to ROS format\n        // In practice, this would use ROS-TCP-Connector to send image to ROS system\n        // For this example, we\'ll just log that image conversion would happen\n        Debug.Log("Image captured and ready for ROS conversion");\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h3,{id:"352-lidar-sensor-simulation",children:"3.5.2 LIDAR Sensor Simulation"}),"\n",(0,o.jsx)(e.p,{children:"Creating LIDAR sensors using Unity's raycast system:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// LIDAR sensor simulation\nusing UnityEngine;\nusing System.Collections.Generic;\n\npublic class UnityLIDARSensor : MonoBehaviour\n{\n    [Header("LIDAR Configuration")]\n    public float scanRange = 30f;\n    public int horizontalResolution = 720;\n    public int verticalResolution = 1;\n    public float updateRate = 10f;\n    public LayerMask detectionLayers = -1; // All layers by default\n    \n    [Header("Noise Configuration")]\n    public float rangeNoise = 0.01f;\n    \n    private float updateInterval;\n    private float lastUpdate;\n    private float horizontalAngleIncrement;\n    private List<float> scanData;\n\n    void Start()\n    {\n        updateInterval = 1.0f / updateRate;\n        horizontalAngleIncrement = 360.0f / horizontalResolution;\n        scanData = new List<float>(horizontalResolution);\n    }\n\n    void Update()\n    {\n        if (Time.time - lastUpdate >= updateInterval)\n        {\n            PerformScan();\n            lastUpdate = Time.time;\n        }\n    }\n\n    void PerformScan()\n    {\n        scanData.Clear();\n        \n        for (int i = 0; i < horizontalResolution; i++)\n        {\n            float angle = i * horizontalAngleIncrement * Mathf.Deg2Rad;\n            float range = PerformRaycast(angle, 0); // 0 elevation for 2D LIDAR\n            scanData.Add(range);\n        }\n        \n        // Publish scan data (would connect to ROS in real implementation)\n        PublishScanData();\n    }\n\n    float PerformRaycast(float horizontalAngle, float verticalAngle)\n    {\n        // Calculate ray direction based on angles\n        Vector3 direction = new Vector3(\n            Mathf.Cos(verticalAngle) * Mathf.Cos(horizontalAngle),\n            Mathf.Sin(verticalAngle),\n            Mathf.Cos(verticalAngle) * Mathf.Sin(horizontalAngle)\n        );\n        \n        direction = transform.TransformDirection(direction);\n        \n        // Perform raycast\n        if (Physics.Raycast(transform.position, direction, out RaycastHit hit, scanRange, detectionLayers))\n        {\n            float range = hit.distance;\n            \n            // Add noise to measurement\n            range += Random.Range(-rangeNoise, rangeNoise);\n            \n            return Mathf.Clamp(range, 0f, scanRange);\n        }\n        else\n        {\n            // Return max range if no hit\n            return scanRange;\n        }\n    }\n\n    void PublishScanData()\n    {\n        // In a real implementation, convert scan data to ROS LaserScan message\n        // and publish via ROS-TCP-Connector\n        Debug.Log($"LIDAR scan completed with {scanData.Count} points");\n    }\n\n    // Visualization method for debugging\n    void OnDrawGizmosSelected()\n    {\n        if (scanData != null && scanData.Count > 0)\n        {\n            for (int i = 0; i < scanData.Count; i++)\n            {\n                float angle = i * horizontalAngleIncrement * Mathf.Deg2Rad;\n                Vector3 direction = new Vector3(Mathf.Cos(angle), 0, Mathf.Sin(angle));\n                direction = transform.TransformDirection(direction);\n                \n                float range = scanData[i];\n                if (range < scanRange)\n                {\n                    Gizmos.color = Color.red;\n                    Gizmos.DrawRay(transform.position, direction * range);\n                }\n                else\n                {\n                    Gizmos.color = Color.green;\n                    Gizmos.DrawRay(transform.position, direction * scanRange);\n                }\n            }\n        }\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h3,{id:"353-imu-sensor-simulation",children:"3.5.3 IMU Sensor Simulation"}),"\n",(0,o.jsx)(e.p,{children:"Implementing IMU sensors using Unity's physics system:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// IMU sensor simulation\nusing UnityEngine;\n\npublic class UnityIMUSensor : MonoBehaviour\n{\n    [Header("IMU Configuration")]\n    public float updateRate = 100f; // Hz\n    public Vector3 noiseLinearAcceleration = Vector3.one * 0.017f; // m/s^2\n    public Vector3 noiseAngularVelocity = Vector3.one * 0.0002f; // rad/s\n    public Vector3 noiseOrientation = Vector3.one * 0.01f;         // rad\n    \n    [Header("Gravity Compensation")]\n    public bool compensateGravity = true;\n\n    private float updateInterval;\n    private float lastUpdate;\n    private Rigidbody attachedRigidbody;\n    \n    // These would be published as ROS messages in real implementation\n    public Vector3 linearAcceleration;\n    public Vector3 angularVelocity;\n    public Quaternion orientation;\n\n    void Start()\n    {\n        updateInterval = 1.0f / updateRate;\n        attachedRigidbody = GetComponent<Rigidbody>();\n        \n        // If no rigidbody attached, try to find one in parent\n        if (attachedRigidbody == null)\n        {\n            attachedRigidbody = GetComponentInParent<Rigidbody>();\n        }\n    }\n\n    void Update()\n    {\n        if (Time.time - lastUpdate >= updateInterval)\n        {\n            UpdateIMUReading();\n            lastUpdate = Time.time;\n        }\n    }\n\n    void UpdateIMUReading()\n    {\n        if (attachedRigidbody != null)\n        {\n            // Get orientation (relative to world or other reference)\n            orientation = transform.rotation;\n            \n            // Get angular velocity from rigidbody if attached\n            if (attachedRigidbody != null)\n            {\n                // Angular velocity in the local frame\n                angularVelocity = transform.InverseTransformDirection(attachedRigidbody.angularVelocity);\n            }\n            else\n            {\n                angularVelocity = Vector3.zero;\n            }\n            \n            // Linear acceleration (calculated from change in velocity)\n            if (attachedRigidbody != null)\n            {\n                // Get linear acceleration in local frame\n                Vector3 worldAcc = attachedRigidbody.velocity / Time.deltaTime;\n                linearAcceleration = transform.InverseTransformDirection(worldAcc);\n                \n                // Optionally remove gravity from linear acceleration\n                if (compensateGravity)\n                {\n                    Vector3 gravityVector = Physics.gravity;\n                    Vector3 gravityLocal = transform.InverseTransformDirection(gravityVector);\n                    linearAcceleration -= gravityLocal;\n                }\n            }\n            else\n            {\n                linearAcceleration = Physics.gravity;\n                if (compensateGravity) linearAcceleration = Vector3.zero;\n            }\n        }\n        else\n        {\n            // If no rigidbody, use transform changes (less accurate)\n            orientation = transform.rotation;\n            linearAcceleration = (transform.position - transform.position) / Time.deltaTime; // Simplified\n            angularVelocity = Vector3.zero;\n        }\n        \n        // Add noise to measurements\n        AddNoiseToMeasurements();\n        \n        // Publish IMU data (would connect to ROS in real implementation)\n        PublishIMUData();\n    }\n\n    void AddNoiseToMeasurements()\n    {\n        linearAcceleration += new Vector3(\n            Random.Range(-noiseLinearAcceleration.x, noiseLinearAcceleration.x),\n            Random.Range(-noiseLinearAcceleration.y, noiseLinearAcceleration.y),\n            Random.Range(-noiseLinearAcceleration.z, noiseLinearAcceleration.z)\n        );\n        \n        angularVelocity += new Vector3(\n            Random.Range(-noiseAngularVelocity.x, noiseAngularVelocity.x),\n            Random.Range(-noiseAngularVelocity.y, noiseAngularVelocity.y),\n            Random.Range(-noiseAngularVelocity.z, noiseAngularVelocity.z)\n        );\n        \n        // Add noise to orientation (simplified approach)\n        orientation = Quaternion.Euler(\n            orientation.eulerAngles.x + Random.Range(-noiseOrientation.x, noiseOrientation.x),\n            orientation.eulerAngles.y + Random.Range(-noiseOrientation.y, noiseOrientation.y),\n            orientation.eulerAngles.z + Random.Range(-noiseOrientation.z, noiseOrientation.z)\n        );\n    }\n\n    void PublishIMUData()\n    {\n        // In a real implementation, convert to ROS sensor_msgs/Imu message\n        // and publish via ROS-TCP-Connector\n        Debug.Log($"IMU: Acc={linearAcceleration}, Vel={angularVelocity}");\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h2,{id:"36-ros-integration-with-unity",children:"3.6 ROS Integration with Unity"}),"\n",(0,o.jsx)(e.h3,{id:"361-ros-tcp-connector-setup",children:"3.6.1 ROS-TCP-Connector Setup"}),"\n",(0,o.jsx)(e.p,{children:"Integrating Unity with ROS systems:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// ROS communication interface\nusing UnityEngine;\nusing System.Collections;\nusing System.Collections.Generic;\nusing System.Net.Sockets;\nusing System.Text;\nusing Newtonsoft.Json;\n\npublic class ROSCommunication : MonoBehaviour\n{\n    [Header("ROS Connection")]\n    public string rosBridgeIP = "127.0.0.1";\n    public int rosBridgePort = 9090;\n    \n    private TcpClient rosClient;\n    private NetworkStream stream;\n    private bool isConnected = false;\n\n    void Start()\n    {\n        ConnectToROSBridge();\n    }\n\n    void ConnectToROSBridge()\n    {\n        try\n        {\n            rosClient = new TcpClient(rosBridgeIP, rosBridgePort);\n            stream = rosClient.GetStream();\n            isConnected = true;\n            Debug.Log("Connected to ROS bridge");\n        }\n        catch (System.Exception e)\n        {\n            Debug.LogError("Failed to connect to ROS bridge: " + e.Message);\n        }\n    }\n\n    public void PublishToTopic(string topic, string messageType, object message)\n    {\n        if (!isConnected) return;\n\n        // Create ROS bridge message\n        var rosMessage = new\n        {\n            op = "publish",\n            topic = topic,\n            type = messageType,\n            msg = message\n        };\n\n        string jsonMessage = JsonConvert.SerializeObject(rosMessage);\n        byte[] data = Encoding.UTF8.GetBytes(jsonMessage + "\\n");\n\n        try\n        {\n            stream.Write(data, 0, data.Length);\n        }\n        catch (System.Exception e)\n        {\n            Debug.LogError("Failed to publish message: " + e.Message);\n        }\n    }\n\n    public void SubscribeToTopic(string topic, string messageType)\n    {\n        if (!isConnected) return;\n\n        var subscribeMessage = new\n        {\n            op = "subscribe",\n            topic = topic,\n            type = messageType\n        };\n\n        string jsonMessage = JsonConvert.SerializeObject(subscribeMessage);\n        byte[] data = Encoding.UTF8.GetBytes(jsonMessage + "\\n");\n\n        try\n        {\n            stream.Write(data, 0, data.Length);\n        }\n        catch (System.Exception e)\n        {\n            Debug.LogError("Failed to subscribe to topic: " + e.Message);\n        }\n    }\n\n    void OnApplicationQuit()\n    {\n        if (rosClient != null)\n        {\n            rosClient.Close();\n        }\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h3,{id:"362-message-conversion-utilities",children:"3.6.2 Message Conversion Utilities"}),"\n",(0,o.jsx)(e.p,{children:"Converting between Unity and ROS message formats:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// Message conversion utilities\nusing UnityEngine;\nusing System.Collections.Generic;\n\npublic static class ROSMessageConverter\n{\n    // Convert Unity Vector3 to ROS geometry_msgs/Point\n    public static Dictionary<string, object> Vector3ToROSPoint(Vector3 unityVector)\n    {\n        return new Dictionary<string, object>\n        {\n            {"x", unityVector.x},\n            {"y", unityVector.z},  // Unity\'s z is ROS\'s y (assuming coordinate transformation)\n            {"z", unityVector.y}   // Unity\'s y is ROS\'s z\n        };\n    }\n\n    // Convert Unity Quaternion to ROS geometry_msgs/Quaternion\n    public static Dictionary<string, object> QuaternionToROSQuaternion(Quaternion unityQuat)\n    {\n        return new Dictionary<string, object>\n        {\n            {"x", unityQuat.x},\n            {"y", unityQuat.z},  // Coordinate transformation\n            {"z", unityQuat.y},\n            {"w", unityQuat.w}\n        };\n    }\n\n    // Convert ROS timestamp to Unity\n    public static double GetROSTimestamp()\n    {\n        System.DateTime epochStart = new System.DateTime(1970, 1, 1, 0, 0, 0, System.DateTimeKind.Utc);\n        double timestamp = (System.DateTime.UtcNow - epochStart).TotalSeconds;\n        return timestamp;\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h2,{id:"37-performance-optimization",children:"3.7 Performance Optimization"}),"\n",(0,o.jsx)(e.h3,{id:"371-rendering-optimization",children:"3.7.1 Rendering Optimization"}),"\n",(0,o.jsx)(e.p,{children:"Optimizing Unity for real-time robotics simulation:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// Rendering optimization settings\nusing UnityEngine;\n\npublic class RenderingOptimization : MonoBehaviour\n{\n    [Header("LOD Settings")]\n    public float lodBias = 1.0f;\n    public int maximumLODLevel = 0;\n    \n    [Header("Occlusion Culling")]\n    public bool enableOcclusionCulling = true;\n    \n    [Header("Quality Settings")]\n    public float shadowDistance = 50f;\n    public int shadowResolution = 1024;\n    public int shadowCascades = 2;\n    \n    [Header("Dynamic Batching")]\n    public bool enableDynamicBatching = true;\n    public bool enableStaticBatching = true;\n\n    void Start()\n    {\n        ApplyOptimizations();\n    }\n\n    void ApplyOptimizations()\n    {\n        // Apply LOD bias\n        QualitySettings.lodBias = lodBias;\n        QualitySettings.maximumLODLevel = maximumLODLevel;\n        \n        // Configure shadow settings for performance\n        QualitySettings.shadowDistance = shadowDistance;\n        QualitySettings.shadowResolution = (ShadowResolution)shadowResolution;\n        QualitySettings.shadowCascades = shadowCascades;\n        \n        // Note: Batching settings are project-wide and set in Quality Settings\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h3,{id:"372-physics-optimization",children:"3.7.2 Physics Optimization"}),"\n",(0,o.jsx)(e.p,{children:"Optimizing physics simulation for real-time performance:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// Physics optimization for robotics simulation\nusing UnityEngine;\n\npublic class PhysicsOptimization : MonoBehaviour\n{\n    [Header("Physics Settings")]\n    public int solverIterations = 6; // Balance between stability and performance\n    public int solverVelocityIterations = 1;\n    public float sleepThreshold = 0.005f;\n    public float contactOffset = 0.01f;\n    \n    [Header("Simulation Settings")]\n    public int threadCount = 0; // 0 means use default\n    public float fixedDeltaTime = 0.02f; // 50 Hz physics updates\n\n    void Start()\n    {\n        OptimizePhysics();\n    }\n\n    void OptimizePhysics()\n    {\n        Physics.defaultSolverIterations = solverIterations;\n        Physics.defaultSolverVelocityIterations = solverVelocityIterations;\n        Physics.sleepThreshold = sleepThreshold;\n        Physics.defaultContactOffset = contactOffset;\n        \n        // Set physics time step\n        Time.fixedDeltaTime = fixedDeltaTime;\n        \n        // Adjust thread count if needed\n        if (threadCount > 0)\n        {\n            Physics.defaultSolverThreadCount = threadCount;\n        }\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h2,{id:"38-advanced-simulation-features",children:"3.8 Advanced Simulation Features"}),"\n",(0,o.jsx)(e.h3,{id:"381-domain-randomization",children:"3.8.1 Domain Randomization"}),"\n",(0,o.jsx)(e.p,{children:"Implementing domain randomization to improve sim-to-real transfer:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// Domain randomization implementation\nusing UnityEngine;\nusing System.Collections;\n\npublic class DomainRandomization : MonoBehaviour\n{\n    [Header("Material Randomization")]\n    public Material[] baseMaterials;\n    public Color[] randomColors;\n    public float randomRoughnessRange = 0.5f;\n    \n    [Header("Lighting Randomization")]\n    public Light[] lightsToRandomize;\n    public float intensityRange = 0.5f;\n    \n    [Header("Object Randomization")]\n    public GameObject[] objectsToRandomize;\n    public float positionJitter = 0.1f;\n    public float rotationJitter = 5f;\n    \n    [Header("Timing")]\n    public float randomizationInterval = 10f; // seconds\n\n    private float lastRandomization;\n\n    void Start()\n    {\n        lastRandomization = Time.time;\n        RandomizeEnvironment();\n    }\n\n    void Update()\n    {\n        if (Time.time - lastRandomization >= randomizationInterval)\n        {\n            RandomizeEnvironment();\n            lastRandomization = Time.time;\n        }\n    }\n\n    void RandomizeEnvironment()\n    {\n        RandomizeMaterials();\n        RandomizeLighting();\n        RandomizeObjects();\n    }\n\n    void RandomizeMaterials()\n    {\n        foreach (Material mat in baseMaterials)\n        {\n            if (mat != null)\n            {\n                // Randomize color\n                if (randomColors.Length > 0)\n                {\n                    Color randomColor = randomColors[Random.Range(0, randomColors.Length)];\n                    mat.color = randomColor;\n                }\n                \n                // Randomize roughness\n                float randomRoughness = Random.Range(0.5f, 0.5f + randomRoughnessRange);\n                mat.SetFloat("_Metallic", 1.0f - randomRoughness); // Simplified\n            }\n        }\n    }\n\n    void RandomizeLighting()\n    {\n        foreach (Light light in lightsToRandomize)\n        {\n            if (light != null)\n            {\n                float randomIntensity = light.intensity * Random.Range(1f - intensityRange, 1f + intensityRange);\n                light.intensity = Mathf.Clamp(randomIntensity, 0.1f, 5f);\n                \n                // Randomize color within reasonable ranges\n                float hue, saturation, value;\n                Color.RGBToHSV(light.color, out hue, out saturation, out value);\n                hue = Mathf.Clamp01(hue + Random.Range(-0.1f, 0.1f));\n                saturation = Mathf.Clamp01(saturation + Random.Range(-0.1f, 0.1f));\n                light.color = Color.HSVToRGB(hue, saturation, value);\n            }\n        }\n    }\n\n    void RandomizeObjects()\n    {\n        foreach (GameObject obj in objectsToRandomize)\n        {\n            if (obj != null)\n            {\n                // Add small position jitter\n                Vector3 randomPos = obj.transform.position;\n                randomPos.x += Random.Range(-positionJitter, positionJitter);\n                randomPos.y += Random.Range(-positionJitter, positionJitter);\n                randomPos.z += Random.Range(-positionJitter, positionJitter);\n                obj.transform.position = randomPos;\n                \n                // Add small rotation jitter\n                Vector3 randomRot = obj.transform.eulerAngles;\n                randomRot.x += Random.Range(-rotationJitter, rotationJitter);\n                randomRot.y += Random.Range(-rotationJitter, rotationJitter);\n                randomRot.z += Random.Range(-rotationJitter, rotationJitter);\n                obj.transform.eulerAngles = randomRot;\n            }\n        }\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h3,{id:"382-synthetic-data-generation",children:"3.8.2 Synthetic Data Generation"}),"\n",(0,o.jsx)(e.p,{children:"Using Unity Perception for generating training data:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// Synthetic data generation setup\nusing UnityEngine;\nusing Unity.Perception.GroundTruth;\n\n[RequireComponent(typeof(PerceptionCamera))]\npublic class SyntheticDataGenerator : MonoBehaviour\n{\n    [Header("Dataset Configuration")]\n    public string datasetName = "robotics_dataset";\n    public int sequenceId = 0;\n    public bool captureAtFixedIntervals = true;\n    public float captureInterval = 0.5f; // seconds\n\n    [Header("Annotation Types")]\n    public bool captureBoundingBoxes = true;\n    public bool captureSegmentation = true;\n    public bool captureDepth = true;\n\n    private PerceptionCamera perceptionCamera;\n    private float lastCapture;\n    private int frameCount = 0;\n\n    void Start()\n    {\n        SetupPerceptionCamera();\n        lastCapture = Time.time;\n    }\n\n    void Update()\n    {\n        if (captureAtFixedIntervals && Time.time - lastCapture >= captureInterval)\n        {\n            CaptureAnnotations();\n            lastCapture = Time.time;\n        }\n    }\n\n    void SetupPerceptionCamera()\n    {\n        perceptionCamera = GetComponent<PerceptionCamera>();\n        if (perceptionCamera == null)\n        {\n            perceptionCamera = gameObject.AddComponent<PerceptionCamera>();\n        }\n\n        // Configure annotation types\n        perceptionCamera.annotationCaptureSettings.boundingBox2D.enabled = captureBoundingBoxes;\n        perceptionCamera.annotationCaptureSettings.instanceSegmentation.enabled = captureSegmentation;\n        perceptionCamera.annotationCaptureSettings.depth.enabled = captureDepth;\n    }\n\n    void CaptureAnnotations()\n    {\n        // Capture annotations for this frame\n        var captureFrame = new CaptureFrame\n        {\n            sequenceId = sequenceId,\n            timestamp = Time.time,\n            frameId = frameCount++\n        };\n\n        // In a real implementation, this would trigger annotation capture\n        // and save to dataset in appropriate format\n        perceptionCamera.CaptureFrame(captureFrame);\n\n        Debug.Log($"Captured frame {captureFrame.frameId} for sequence {sequenceId}");\n    }\n\n    // Manual capture method\n    public void ManualCapture()\n    {\n        CaptureAnnotations();\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h2,{id:"chapter-summary",children:"Chapter Summary"}),"\n",(0,o.jsx)(e.p,{children:"This chapter provided a comprehensive guide to using Unity for creating visualization-rich simulation environments for robotics applications. We covered Unity setup and configuration, robot model creation, environment design with realistic physics, sensor simulation implementations (camera, LIDAR, IMU), ROS integration using ROS-TCP-Connector, performance optimization techniques, and advanced features like domain randomization and synthetic data generation. Unity's strength lies in its ability to create photorealistic environments for perception-focused robotics applications."}),"\n",(0,o.jsx)(e.h2,{id:"key-terms",children:"Key Terms"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Unity Robotics"}),"\n",(0,o.jsx)(e.li,{children:"Photorealistic Rendering"}),"\n",(0,o.jsx)(e.li,{children:"ROS-TCP-Connector"}),"\n",(0,o.jsx)(e.li,{children:"Domain Randomization"}),"\n",(0,o.jsx)(e.li,{children:"Synthetic Data Generation"}),"\n",(0,o.jsx)(e.li,{children:"Physics Simulation"}),"\n",(0,o.jsx)(e.li,{children:"Sensor Simulation"}),"\n",(0,o.jsx)(e.li,{children:"Perception Training"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"exercises",children:"Exercises"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsx)(e.li,{children:"Create a Unity scene with a simple robot model and export sensor data"}),"\n",(0,o.jsx)(e.li,{children:"Implement domain randomization techniques for a robotic perception task"}),"\n",(0,o.jsx)(e.li,{children:"Set up ROS communication between Unity and a ROS 2 system"}),"\n",(0,o.jsx)(e.li,{children:"Generate synthetic training data for a computer vision pipeline"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"references",children:"References"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:["Unity Robotics Hub: ",(0,o.jsx)(e.a,{href:"https://unity.com/solutions/robotics",children:"https://unity.com/solutions/robotics"})]}),"\n",(0,o.jsx)(e.li,{children:"Unity Perception Package Documentation"}),"\n",(0,o.jsx)(e.li,{children:"ROS-TCP-Connector GitHub Repository"}),"\n",(0,o.jsx)(e.li,{children:"Unity ML-Agents Toolkit Documentation"}),"\n"]})]})}function u(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>r,x:()=>s});var t=i(6540);const o={},a=t.createContext(o);function r(n){const e=t.useContext(a);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:r(n.components),t.createElement(a.Provider,{value:e},n.children)}}}]);